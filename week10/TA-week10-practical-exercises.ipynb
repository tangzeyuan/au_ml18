{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math  # Just ignore this :-)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML - Week 10 - Practical Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "22a39008-e542-438a-83f4-fd54f37017b8"
    }
   },
   "source": [
    "In the exercise below, you will see an example of how a HMM can be represented, and you will implement and experiment with the computation of the joint probability and various decodings as explained in the lectures in week 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "13722c25-cdc1-4ea4-98f0-a779946ce53c"
    }
   },
   "source": [
    "# 1 - Representing a HMM\n",
    "\n",
    "We can represent a HMM as a triple consisting of three matrices: a $K \\times 1$ matrix with the initial state probabilities, a $K \\times K$ matrix with the transition probabilities and a $K \\times |\\Sigma|$ matrix with the emission probabilities. In Python we can write the matrices like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "b9f24259-216a-438c-86e7-aad8cb275bc6"
    }
   },
   "outputs": [],
   "source": [
    "init_probs_7_state = [0.00, 0.00, 0.00, 1.00, 0.00, 0.00, 0.00]\n",
    "\n",
    "trans_probs_7_state = [\n",
    "    [0.00, 0.00, 0.90, 0.10, 0.00, 0.00, 0.00],\n",
    "    [1.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
    "    [0.00, 1.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
    "    [0.00, 0.00, 0.05, 0.90, 0.05, 0.00, 0.00],\n",
    "    [0.00, 0.00, 0.00, 0.00, 0.00, 1.00, 0.00],\n",
    "    [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 1.00],\n",
    "    [0.00, 0.00, 0.00, 0.10, 0.90, 0.00, 0.00],\n",
    "]\n",
    "\n",
    "emission_probs_7_state = [\n",
    "    #   A     C     G     T\n",
    "    [0.30, 0.25, 0.25, 0.20],\n",
    "    [0.20, 0.35, 0.15, 0.30],\n",
    "    [0.40, 0.15, 0.20, 0.25],\n",
    "    [0.25, 0.25, 0.25, 0.25],\n",
    "    [0.20, 0.40, 0.30, 0.10],\n",
    "    [0.30, 0.20, 0.30, 0.20],\n",
    "    [0.15, 0.30, 0.20, 0.35],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0fb33618-de36-44df-8462-14b7e58d3b4b"
    }
   },
   "source": [
    "How do we use these matrices? Remember that we are given some sequence of observations, e.g. like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "ed50140f-2197-43fc-837a-e3799ffe5904"
    }
   },
   "outputs": [],
   "source": [
    "obs_example = 'GTTTCCCAGTGTATATCGAGGGATACTACGTGCATAGTAACATCGGCCAA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2bef7e67-d545-447f-9d0c-7b6078ee627b"
    }
   },
   "source": [
    "To make a lookup in our three matrices we have to translate each symbol in the string to an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "ed1f0acd-83cf-451a-ac94-957ebd8a0d87"
    }
   },
   "outputs": [],
   "source": [
    "def translate_observations_to_indices(obs):\n",
    "    mapping = {'a': 0, 'c': 1, 'g': 2, 't': 3}\n",
    "    return [mapping[symbol.lower()] for symbol in obs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6fcef106-fbc3-4f3d-ab54-5d89271eedf0"
    }
   },
   "source": [
    "Let's try to translate the example above using this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "8604d821-64fb-49e5-8c98-a791c6d42831"
    }
   },
   "outputs": [],
   "source": [
    "obs_example_trans = translate_observations_to_indices(obs_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbpresent": {
     "id": "9a29e558-111a-47bf-a450-2f7a61613ad4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 3, 3, 1, 1, 1, 0, 2, 3, 2, 3, 0, 3, 0, 3, 1, 2, 0, 2, 2, 2, 0, 3, 0, 1, 3, 0, 1, 2, 3, 2, 1, 0, 3, 0, 2, 3, 0, 0, 1, 0, 3, 1, 2, 2, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(obs_example_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function below to translate the indices back to observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate_indices_to_observations(indices):\n",
    "    mapping = ['a', 'c', 'g', 't']\n",
    "    return ''.join(mapping[idx] for idx in indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gtttcccagtgtatatcgagggatactacgtgcatagtaacatcggccaa'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_indices_to_observations(translate_observations_to_indices(obs_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each symbol has been transformed (predictably) into a number which makes it much easier to make lookups in our matrices. We'll do the same thing for a list of states (a path):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate_path_to_indices(path):\n",
    "    return list(map(lambda x: int(x), path))\n",
    "\n",
    "def translate_indices_to_path(indices):\n",
    "    return ''.join([str(i) for i in indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a path through a HMM, we can now translate it to a list of indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 0, 2, 1, 0, 2, 1, 0, 2, 1, 0, 2, 1, 0, 2, 1, 0, 2, 1, 0, 2, 1, 0, 2, 1, 0, 2, 1, 0, 2, 1, 0, 2, 1, 0, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "path_example = '33333333333321021021021021021021021021021021021021'\n",
    "\n",
    "print(translate_path_to_indices(path_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "cf3f4b33-715a-443a-a933-17f29d3ffa75"
    }
   },
   "source": [
    "Finally, we can collect the three matrices in a class to make it easier to work with our HMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbpresent": {
     "id": "43336c35-2a6f-46e9-b86e-0367377dca39"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.9 , 0.1 , 0.  , 0.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.05, 0.9 , 0.05, 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ],\n",
       "       [0.  , 0.  , 0.  , 0.1 , 0.9 , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class hmm:\n",
    "    def __init__(self, init_probs, trans_probs, emission_probs):\n",
    "        self.init_probs = np.array(init_probs)\n",
    "        self.trans_probs = np.atleast_2d(trans_probs)\n",
    "        self.emission_probs = np.atleast_2d(emission_probs)\n",
    "\n",
    "# Collect the matrices in a class.\n",
    "hmm_7_state = hmm(init_probs_7_state, trans_probs_7_state, emission_probs_7_state)\n",
    "\n",
    "# We can now reach the different matrices by their names. E.g.:\n",
    "hmm_7_state.trans_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing, here's another model (which we will refer to as the 3-state model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_probs_3_state = [0.10, 0.80, 0.10]\n",
    "\n",
    "trans_probs_3_state = [\n",
    "    [0.90, 0.10, 0.00],\n",
    "    [0.05, 0.99, 0.05],\n",
    "    [0.00, 0.10, 0.90],\n",
    "]\n",
    "\n",
    "emission_probs_3_state = [\n",
    "    #   A     C     G     T\n",
    "    [0.40, 0.15, 0.20, 0.25],\n",
    "    [0.25, 0.25, 0.25, 0.25],\n",
    "    [0.20, 0.40, 0.30, 0.10],\n",
    "]\n",
    "\n",
    "hmm_3_state = hmm(init_probs_3_state, trans_probs_3_state, emission_probs_3_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "69bf9e07-95ad-429f-b85b-dbb8c1b6c310"
    }
   },
   "source": [
    "# 2 - Validating a HMM (and handling floats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4c1bd08c-2c49-45e6-81e7-5bbbbd2f799c"
    }
   },
   "source": [
    "Before using the model we'll write a function to validate that the model is valid. That is, the matrices should have the right dimensions and the following things should be true:\n",
    "\n",
    "1. The initial probabilities must sum to 1.\n",
    "2. Each row in the matrix of transition probabilities must sum to 1.\n",
    "3. Each row in the matrix of emission probabilities must sum to 1.\n",
    "4. All numbers should be between 0 and 1, inclusive.\n",
    "\n",
    "Write a function `validate_hmm` that given a models returns True if the model is valid, and False otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "2c6c3d32-db85-482b-970c-9bcacd9f5b32"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def validate_hmm(model):\n",
    "    assert ((0 <= model.init_probs) & (model.init_probs <= 1)).all(), \\\n",
    "        \"init_probs does not contain valid probabilities\"\n",
    "    assert ((0 <= model.trans_probs) & (model.trans_probs <= 1)).all(), \\\n",
    "        \"trans_probs does not contain valid probabilities\"\n",
    "    assert ((0 <= model.emission_probs) & (model.emission_probs <= 1)).all(), \\\n",
    "        \"emission_probs does not contain valid probabilities\"\n",
    "    \n",
    "    K = model.trans_probs.shape[0]\n",
    "    assert np.allclose(model.init_probs.sum(), [1.]), \\\n",
    "        \"init_probs did not sum to one\"\n",
    "    assert np.allclose(model.trans_probs.sum(axis=1), np.ones(K)), \\\n",
    "        \"init_probs did not sum to one\"\n",
    "    assert np.allclose(model.emission_probs.sum(axis=1), np.ones(K)), \\\n",
    "        \"init_probs did not sum to one\"\n",
    "    print(\"Model valid!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "05430599-405e-4ffa-add6-84288abe4364"
    }
   },
   "source": [
    "We can now use this function to check whether the example model is a valid model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "nbpresent": {
     "id": "1e3e74d8-7951-4362-af49-240b7d90532d"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model valid!\n"
     ]
    }
   ],
   "source": [
    "validate_hmm(hmm_7_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might run into problems related to summing floating point numbers because summing floating point numbers does not (always) give the expected result as illustrated by the following examples. How do you suggest to deal with this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.15 + 0.30 + 0.20 + 0.35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order of the terms matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.20 + 0.35 + 0.15 + 0.30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it changes the prefix sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44999999999999996"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.15 + 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7000000000000001"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.20 + 0.35 + 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44999999999999996"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.15 + 0.30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On should never compare floating point numbers. They represent only an 'approximation'. Read more about the 'problems' in 'What Every Computer Scientist Should Know About Floating-Point Arithmetic' at:\n",
    "\n",
    "http://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7b9b636c-c901-4ea8-a99d-190a396b2405"
    }
   },
   "source": [
    "# 3 - Computing the Joint Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the joint probability $p({\\bf X}, {\\bf Z}) = p({\\bf x}_1, \\ldots, {\\bf x}_N, {\\bf z}_1, \\ldots, {\\bf z}_N)$ of a hidden Markov model (HMM) can be compute as\n",
    "\n",
    "$$\n",
    "p({\\bf x}_1, \\ldots, {\\bf x}_N, {\\bf z}_1, \\ldots, {\\bf z}_N) = p({\\bf z}_1) \n",
    "\\left[ \\prod_{n=2}^N p({\\bf z}_n \\mid {\\bf z}_{n-1}) \\right]\n",
    "\\prod_{n=1}^N p({\\bf x}_n \\mid {\\bf z}_n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing without log-transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `joint_prob` given a model (e.g. in the representation above) and sequence of observables, ${\\bf X}$, and a sequence of hidden states, ${\\bf Z}$, computes the joint probability cf. the above formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "3769ed05-effc-42d7-ae3b-655ea2082dc3"
    }
   },
   "outputs": [],
   "source": [
    "def joint_prob(model, x, z):\n",
    "    p = model.init_probs[z[0]] * model.emission_probs[z[0], x[0]]\n",
    "    for i in range(1, len(x)):\n",
    "        p *= model.trans_probs[z[i-1], z[i]] * model.emission_probs[z[i], x[i]] \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bf292319-b283-4947-ba29-8db3efea4541"
    }
   },
   "source": [
    "Now compute the joint probability of the ${\\bf X}$ (`x_short`) and ${\\bf Z}$ (`z_short`) below using the 7-state (`hmm_7_state`) model introduced above. (*Remember to translate them first using the appropriate functions introduces above!*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "nbpresent": {
     "id": "51699e6f-c98d-4552-8d21-5e37153bab84"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9114255184318882e-31\n"
     ]
    }
   ],
   "source": [
    "x_short = 'GTTTCCCAGTGTATATCGAGGGATACTACGTGCATAGTAACATCGGCCAA'\n",
    "z_short = '33333333333321021021021021021021021021021021021021'\n",
    "\n",
    "# Your code here ...\n",
    "x = translate_observations_to_indices(x_short)\n",
    "z = translate_path_to_indices(z_short)\n",
    "output_joint_prob = joint_prob(hmm_7_state, x, z)\n",
    "print(output_joint_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "62cc8755-8cf4-4b52-9e47-73395c18e741"
    }
   },
   "source": [
    "## Implementing with log-transformation (i.e. in \"log-space\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "65813762-66da-4d50-8290-197eb23d5c90"
    }
   },
   "source": [
    "Now implement the joint probability function in log space as explained in the lecture. We've given you a log-function that handles $\\log(0)$.\n",
    "\n",
    "Answer: The formula is the following:\n",
    "$$\n",
    "p({\\bf x}_1, \\ldots, {\\bf x}_N, {\\bf z}_1, \\ldots, {\\bf z}_N) = \\log p({\\bf z}_1) +\n",
    "\\sum_{n=2}^N \\log p({\\bf z}_n \\mid {\\bf z}_{n-1}) +\n",
    "\\sum_{n=1}^N p({\\bf x}_n \\mid {\\bf z}_n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "c4e0a0e0-1fec-462d-89ad-3797ba7d24f3"
    }
   },
   "outputs": [],
   "source": [
    "def log(x):\n",
    "    if x == 0:\n",
    "        return float('-inf')\n",
    "    return math.log(x)\n",
    "\n",
    "def joint_prob_log(model, x, z):\n",
    "    p = log(model.init_probs[z[0]]) + log(model.emission_probs[z[0], x[0]])\n",
    "    for i in range(1, len(x)):\n",
    "        p += log(model.trans_probs[z[i-1], z[i]]) + log(model.emission_probs[z[i], x[i]])\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d47a1d9b-de76-41cc-88de-694965dd1ce7"
    }
   },
   "source": [
    "Confirm that the log-space function is correct by comparing the output to the output of `joint_prob`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-70.73228857440486\n"
     ]
    }
   ],
   "source": [
    "# Your code here ...\n",
    "output_joint_prob_log = joint_prob_log(hmm_7_state, x, z)\n",
    "print(output_joint_prob_log)\n",
    "assert log(output_joint_prob) == output_joint_prob_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "06151990-65f6-401e-aa31-7adc39603c4b"
    }
   },
   "source": [
    "## Comparison of Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "10ae159d-95f8-47aa-a42b-6bda8e25a0a2"
    }
   },
   "source": [
    "Now that you have two ways to compute the joint probability given a model, a sequence of observations, and a sequence of hidden states, try to make an experiment to figure out how long a sequence can be before it becomes essential to use the log-transformed version. For this experiment we'll use two longer sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_long = 'TGAGTATCACTTAGGTCTATGTCTAGTCGTCTTTCGTAATGTTTGGTCTTGTCACCAGTTATCCTATGGCGCTCCGAGTCTGGTTCTCGAAATAAGCATCCCCGCCCAAGTCATGCACCCGTTTGTGTTCTTCGCCGACTTGAGCGACTTAATGAGGATGCCACTCGTCACCATCTTGAACATGCCACCAACGAGGTTGCCGCCGTCCATTATAACTACAACCTAGACAATTTTCGCTTTAGGTCCATTCACTAGGCCGAAATCCGCTGGAGTAAGCACAAAGCTCGTATAGGCAAAACCGACTCCATGAGTCTGCCTCCCGACCATTCCCATCAAAATACGCTATCAATACTAAAAAAATGACGGTTCAGCCTCACCCGGATGCTCGAGACAGCACACGGACATGATAGCGAACGTGACCAGTGTAGTGGCCCAGGGGAACCGCCGCGCCATTTTGTTCATGGCCCCGCTGCCGAATATTTCGATCCCAGCTAGAGTAATGACCTGTAGCTTAAACCCACTTTTGGCCCAAACTAGAGCAACAATCGGAATGGCTGAAGTGAATGCCGGCATGCCCTCAGCTCTAAGCGCCTCGATCGCAGTAATGACCGTCTTAACATTAGCTCTCAACGCTATGCAGTGGCTTTGGTGTCGCTTACTACCAGTTCCGAACGTCTCGGGGGTCTTGATGCAGCGCACCACGATGCCAAGCCACGCTGAATCGGGCAGCCAGCAGGATCGTTACAGTCGAGCCCACGGCAATGCGAGCCGTCACGTTGCCGAATATGCACTGCGGGACTACGGACGCAGGGCCGCCAACCATCTGGTTGACGATAGCCAAACACGGTCCAGAGGTGCCCCATCTCGGTTATTTGGATCGTAATTTTTGTGAAGAACACTGCAAACGCAAGTGGCTTTCCAGACTTTACGACTATGTGCCATCATTTAAGGCTACGACCCGGCTTTTAAGACCCCCACCACTAAATAGAGGTACATCTGA'\n",
    "z_long = '3333321021021021021021021021021021021021021021021021021021021021021021033333333334564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564563210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210321021021021021021021021033334564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564563333333456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456332102102102102102102102102102102102102102102102102102102102102102102102102102102102102102102102103210210210210210210210210210210210210210210210210210210210210210'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "85880ba1-bc5b-455a-9335-000678ea9b0e"
    }
   },
   "source": [
    "Now compute the joint probability with `joint_prob` using both the 3-state (hmm_3_state) and the 7-state (hmm_7_state) model introduced above, and see when it breaks (i.e. when it wrongfully becomes 0). Does this make sense? No as 3-state only have 3 possible states for z, whereas here in this example it has 7. \n",
    "\n",
    "Here's some code to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "nbpresent": {
     "id": "c558e928-6660-4b69-8db3-3341e8b19dba"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmm_3_state broke for sequence length 100\n",
      "hmm_7_state broke for sequence length 530\n"
     ]
    }
   ],
   "source": [
    "b3 = True\n",
    "b7 = True\n",
    "for i in range(100, len(x_long), 1):\n",
    "    x = x_long[:i]\n",
    "    z = z_long[:i]\n",
    "\n",
    "    x_trans = translate_observations_to_indices(x)\n",
    "    z_trans = translate_path_to_indices(z)\n",
    "    \n",
    "    # Make your experiment here...\n",
    "    # Ignore 3 state, as z_long have 7 states.\n",
    "    z_trans_3_state = list(map(lambda x: x % 3, z_trans))\n",
    "    if b3 & (joint_prob(hmm_3_state, x_trans, z_trans_3_state) == 0):\n",
    "        print(\"hmm_3_state broke for sequence length\", i)\n",
    "        b3 = False\n",
    "    if b7 & (joint_prob(hmm_7_state, x_trans, z_trans) == 0):\n",
    "        print(\"hmm_7_state broke for sequence length\", i)\n",
    "        b7 = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below you should state for which $i$ computing the joint probability (for the two models considered) using `joint_prob` wrongfully becomes 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n",
    "\n",
    "For the 3-state model, `joint_prob` becomes 0 for **i = 100 **.\n",
    "\n",
    "For the 7-state model, `joint_prob` becomes 0 for **i = 530 **."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Viterbi Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you will implement and experiment with the Viterbi algorithm. The implementation has been split into three parts:\n",
    "\n",
    "1. Fill out the $\\omega$ table using the recursion presented at the lecture.\n",
    "2. Find the state with the highest probability after observing the entire sequence of observations.\n",
    "3. Backtrack from the state found in the previous step to obtain the optimal path.\n",
    "\n",
    "We'll be working with the 7-state model (`hmm_7_state`) and the helper function for translating between observations, hidden states, and indicies, as introduced above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, you're given the function below that constructs a table of a specific size filled with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_table(m, n):\n",
    "    \"\"\"Make a table with `m` rows and `n` columns filled with zeros.\"\"\"\n",
    "    return [[0] * n for _ in range(m)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll be testing your code with the same two sequences as above, i.e:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_short = 'GTTTCCCAGTGTATATCGAGGGATACTACGTGCATAGTAACATCGGCCAA'\n",
    "z_short = '33333333333321021021021021021021021021021021021021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_long = 'TGAGTATCACTTAGGTCTATGTCTAGTCGTCTTTCGTAATGTTTGGTCTTGTCACCAGTTATCCTATGGCGCTCCGAGTCTGGTTCTCGAAATAAGCATCCCCGCCCAAGTCATGCACCCGTTTGTGTTCTTCGCCGACTTGAGCGACTTAATGAGGATGCCACTCGTCACCATCTTGAACATGCCACCAACGAGGTTGCCGCCGTCCATTATAACTACAACCTAGACAATTTTCGCTTTAGGTCCATTCACTAGGCCGAAATCCGCTGGAGTAAGCACAAAGCTCGTATAGGCAAAACCGACTCCATGAGTCTGCCTCCCGACCATTCCCATCAAAATACGCTATCAATACTAAAAAAATGACGGTTCAGCCTCACCCGGATGCTCGAGACAGCACACGGACATGATAGCGAACGTGACCAGTGTAGTGGCCCAGGGGAACCGCCGCGCCATTTTGTTCATGGCCCCGCTGCCGAATATTTCGATCCCAGCTAGAGTAATGACCTGTAGCTTAAACCCACTTTTGGCCCAAACTAGAGCAACAATCGGAATGGCTGAAGTGAATGCCGGCATGCCCTCAGCTCTAAGCGCCTCGATCGCAGTAATGACCGTCTTAACATTAGCTCTCAACGCTATGCAGTGGCTTTGGTGTCGCTTACTACCAGTTCCGAACGTCTCGGGGGTCTTGATGCAGCGCACCACGATGCCAAGCCACGCTGAATCGGGCAGCCAGCAGGATCGTTACAGTCGAGCCCACGGCAATGCGAGCCGTCACGTTGCCGAATATGCACTGCGGGACTACGGACGCAGGGCCGCCAACCATCTGGTTGACGATAGCCAAACACGGTCCAGAGGTGCCCCATCTCGGTTATTTGGATCGTAATTTTTGTGAAGAACACTGCAAACGCAAGTGGCTTTCCAGACTTTACGACTATGTGCCATCATTTAAGGCTACGACCCGGCTTTTAAGACCCCCACCACTAAATAGAGGTACATCTGA'\n",
    "z_long = '3333321021021021021021021021021021021021021021021021021021021021021021033333333334564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564563210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210321021021021021021021021033334564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564563333333456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456332102102102102102102102102102102102102102102102102102102102102102102102102102102102102102102102103210210210210210210210210210210210210210210210210210210210210210'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to translate these sequences to indices before using them with your algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing without log-transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will implement the algorithm without log-transformation. This will cause issues with numerical stability (like above when computing the joint probability), so we will use the log-transformation trick to fix this in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation of the $\\omega$ table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_w(model, x):\n",
    "    K = len(model.init_probs)\n",
    "    N = len(x)\n",
    "    \n",
    "    # w[k][n] = w(zn), k x n\n",
    "    # w = make_table(K, N)\n",
    "    w = np.zeros((K, N))\n",
    "    \n",
    "    # Base case: fill out w[i][0] for i = 0..k-1\n",
    "    # w(z1) = p(z1)p(x1|z1)\n",
    "    for i in range(K):\n",
    "        w[i, 0] = model.init_probs[i]*model.emission_probs[i, x[0]]\n",
    "    \n",
    "    \n",
    "    # Inductive case: fill out w[i][j] for i = 0..k, j = 1..n\n",
    "    # w(zn) = p(xn|zn)*max_(zn-1) w(zn-1)p(zn|zn-1)\n",
    "    for n in range(1, N):\n",
    "        for k in range(K):\n",
    "            for j in range(K):\n",
    "                w[k, n] = max(w[k, n], model.emission_probs[k, x[n]] * w[j, n-1] * model.trans_probs[j, k])\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the joint probability of an optimal path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, write a function that given the $\\omega$-table, returns the probability of an optimal path through the HMM. As explained in the lecture, this corresponds to finding the highest probability in the last column of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def opt_path_prob_log(w):\n",
    "    return np.max(w[:, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test your implementation in the box below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.911425518431887e-31\n"
     ]
    }
   ],
   "source": [
    "w = compute_w(hmm_7_state, translate_observations_to_indices(x_short))\n",
    "print(opt_path_prob(w))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for `x_long`. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Your code here ...\n",
    "w = compute_w(hmm_7_state, translate_observations_to_indices(x_long))\n",
    "print(opt_path_prob(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining an optimal path through backtracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement backtracking to find a most probable path of hidden states given the $\\omega$-table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backtrack(w, model, x):\n",
    "    N = w.shape[1]\n",
    "    # z[1..N] = undef\n",
    "    z = np.empty((N), dtype=int)\n",
    "    \n",
    "    # z[N] = arg max_k w[k][N]\n",
    "    z[N-1] = np.argmax(w[:, N-1])\n",
    "\n",
    "    # z[n] = arg max_k (p(x[n+1]|z[n+1]) * w[k][n] * p(z[n+1]|k))\n",
    "    for n in range(N-2, -1, -1):\n",
    "        emission_prob = model.emission_probs[z[n+1], x[n+1]]\n",
    "        trans_probs = [row[z[n+1]] for row in model.trans_probs]\n",
    "        z[n] = np.argmax(emission_prob * w[:, n] * trans_probs)\n",
    "\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 3 3 3 3 3 3 3 3 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2\n",
      " 1 0 2 1 0 2 1 0 2 1 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "x_indices = translate_observations_to_indices(x_short)\n",
    "w = compute_w(hmm_7_state, x_indices)\n",
    "z_viterbi = backtrack(w, hmm_7_state, x_indices)\n",
    "print(z_viterbi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for `x_long`. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 3 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1\n",
      " 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 3 3 3\n",
      " 3 3 3 3 3 3 3 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6\n",
      " 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4\n",
      " 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5\n",
      " 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 3 2 1 0 2 1 0 2 1 0 2 1\n",
      " 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0\n",
      " 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2\n",
      " 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1\n",
      " 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0\n",
      " 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2\n",
      " 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1\n",
      " 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0\n",
      " 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2\n",
      " 1 0 2 1 0 2 1 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "# Your code here ...\n",
    "x_indices = translate_observations_to_indices(x_long)\n",
    "w = compute_w(hmm_7_state, x_indices)\n",
    "z_viterbi = backtrack(w, hmm_7_state, x_indices)\n",
    "print(z_viterbi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing with log-transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement the Viterbi algorithm with log transformation. The steps are the same as above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation of the $\\omega$ table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_w_log(model, x):\n",
    "    K = len(model.init_probs)\n",
    "    N = len(x)\n",
    "    \n",
    "    # w[k][n] = w(zn), k x n\n",
    "    # w = make_table(K, N)\n",
    "    w = np.zeros((K, N))\n",
    "    \n",
    "    # Base case: fill out w[i][0] for i = 0..k-1\n",
    "    for i in range(K):\n",
    "        w[i, 0] = log(model.init_probs[i]) + log(model.emission_probs[i, x[0]])\n",
    "    \n",
    "    # Inductive case: fill out w[i][j] for i = 0..k, j = 1..n\n",
    "    for n in range(1, N):\n",
    "        for k in range(K):\n",
    "            w[k, n] = -np.inf  # log probs go negative\n",
    "            for j in range(K):         \n",
    "                w[k, n] = max(w[k, n], log(model.emission_probs[k, x[n]]) + w[j, n-1] + log(model.trans_probs[j, k]))\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the (log transformed) joint probability of an optimal path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def opt_path_prob_log(w):\n",
    "    return max([row[-1] for row in w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-70.73228857440486"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = compute_w_log(hmm_7_state, translate_observations_to_indices(x_short))\n",
    "\n",
    "opt_path_prob_log(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for `x_long`. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1406.7209253880144"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here ...\n",
    "w = compute_w_log(hmm_7_state, translate_observations_to_indices(x_long))\n",
    "\n",
    "opt_path_prob_log(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining an optimal path through backtracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backtrack_log(w, model, x):\n",
    "    N = w.shape[1]\n",
    "    # z[1..N] = undef\n",
    "    z = np.empty((N), dtype=int)\n",
    "    \n",
    "    # z[N] = arg max_k w[k][N]\n",
    "    z[N-1] = np.argmax(w[:, N-1])\n",
    "\n",
    "    # z[n] = arg max_k (p(x[n+1]|z[n+1]) * w[k][n] * p(z[n+1]|k))\n",
    "    for n in range(N-2, -1, -1):\n",
    "        emission_prob = log(model.emission_probs[z[n+1], x[n+1]])\n",
    "        trans_probs = [log(row[z[n+1]]) for row in model.trans_probs]\n",
    "        z[n] = np.argmax(emission_prob + w[:, n] + trans_probs)\n",
    "\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 3 3 3 3 3 3 3 3 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2\n",
      " 1 0 2 1 0 2 1 0 2 1 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "w = compute_w_log(hmm_7_state, translate_observations_to_indices(x_short))\n",
    "z_viterbi_log = backtrack_log(w, hmm_7_state, translate_observations_to_indices(x_short))\n",
    "print(z_viterbi_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for `x_long`. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 3 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1\n",
      " 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 3 3 3\n",
      " 3 3 3 3 3 3 3 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6\n",
      " 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4\n",
      " 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5\n",
      " 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 3 2 1 0 2 1 0 2 1 0 2 1\n",
      " 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0\n",
      " 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2\n",
      " 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1\n",
      " 0 2 1 0 2 1 0 3 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 3 3 3 3 4\n",
      " 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5\n",
      " 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6\n",
      " 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4\n",
      " 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5\n",
      " 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6\n",
      " 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4\n",
      " 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5\n",
      " 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6\n",
      " 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4\n",
      " 5 6 4 5 6 4 5 6 4 5 6 4 5 6 3 3 3 3 3 3 3 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4\n",
      " 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5\n",
      " 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6\n",
      " 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 3 3 2 1 0 2 1 0 2 1 0 2 1\n",
      " 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0\n",
      " 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2\n",
      " 1 0 2 1 0 2 1 0 2 1 0 3 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2\n",
      " 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "# Your code here ...\n",
    "w = compute_w_log(hmm_7_state, translate_observations_to_indices(x_long))\n",
    "z_viterbi_log = backtrack_log(w, hmm_7_state, translate_observations_to_indices(x_long))\n",
    "print(z_viterbi_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about how to verify that your implementations of Viterbi (i.e. `compute_w`, `opt_path_prob`, `backtrack`, and there log-transformed variants `compute_w_log`, `opt_path_prob_log`, `backtrack_log`) are correct.\n",
    "\n",
    "One thing that should hold is that the probability of a most likely path as computed by `opt_path_prob` (or `opt_path_prob_long`) for a given sequence of observables (e.g. `x_short` or `x_long`) should be equal to the joint probability of a corersponding most probable path as found by `backtrack` (or `backtrack_log`) and the given sequence of observables. Why?\n",
    "\n",
    "Answer: In `opt_path_prob` finds the probability of the most likely path. `backtrack` finds the most likely path. So the joint probability of this path should equal the probability of the most likely path.\n",
    "\n",
    "opt_path_prob is the max in the last column in omega table:\n",
    "$$\n",
    "\\max_{z_N} \\omega(z_N) = \\max_{z_N}\\max_{z_1, \\dots, z_{N-1}} p(x_1, \\dots, x_N, z_1, \\dots, z_N) = \\max_{Z} P(X, Z) = P(X, Z^\\star)\n",
    "$$\n",
    "\n",
    "Backtracking:\n",
    "$$\n",
    "Z^\\star = \\arg \\max_{Z} p(X, Z)\n",
    "$$\n",
    "\n",
    "So we see that if we compute the join probability of $P(X, Z^\\star)$, this exactly equals the result of opt_path_prob.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Make an experiment that validates that this is the case for your implementations of Viterbi and `x_short` and `x_long`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt_path_prob: 1.911425518431887e-31\n",
      "backtrack joint prob: 1.9114255184318882e-31\n",
      "opt_path_prob: 0.0\n",
      "backtrack joint prob: 0.0\n",
      "opt_path_prob_log: -70.73228857440486\n",
      "backtrack joint prob log: -70.73228857440486\n",
      "opt_path_prob_log: -1406.7209253880144\n",
      "backtrack joint prob log: -1406.7209253880178\n"
     ]
    }
   ],
   "source": [
    "# Your code here ...\n",
    "\n",
    "def check_opt_path_prob_equals_joint_backtrack(model, x):\n",
    "    x = translate_observations_to_indices(x)\n",
    "    w = compute_w(model, x)\n",
    "    most_likely_path_prob = opt_path_prob(w)\n",
    "    backtrack_path = backtrack(w, model, x)\n",
    "    backtrack_joint_prob = joint_prob(model, x, backtrack_path)\n",
    "    \n",
    "    print('opt_path_prob:', most_likely_path_prob)\n",
    "    print('backtrack joint prob:', backtrack_joint_prob)\n",
    "    assert math.isclose(most_likely_path_prob, backtrack_joint_prob)\n",
    "    \n",
    "def check_opt_path_prob_equals_joint_backtrack_log(model, x):\n",
    "    x = translate_observations_to_indices(x)\n",
    "    w = compute_w_log(model, x)\n",
    "    most_likely_path_prob = opt_path_prob_log(w)\n",
    "    backtrack_path = backtrack_log(w, model, x)\n",
    "    backtrack_joint_prob = joint_prob_log(model, x, backtrack_path)\n",
    "\n",
    "    print('opt_path_prob_log:', most_likely_path_prob)\n",
    "    print('backtrack joint prob log:', backtrack_joint_prob)\n",
    "    assert math.isclose(most_likely_path_prob, backtrack_joint_prob), \"Joint backtrack did not equal opt path prob\"\n",
    "\n",
    "check_opt_path_prob_equals_joint_backtrack(hmm_7_state, x_short)\n",
    "check_opt_path_prob_equals_joint_backtrack(hmm_7_state, x_long)\n",
    "\n",
    "check_opt_path_prob_equals_joint_backtrack_log(hmm_7_state, x_short)\n",
    "check_opt_path_prob_equals_joint_backtrack_log(hmm_7_state, x_long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does log transformation matter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an experiment that investigates how long the input string can be before `backtrack` and `backtrack_log` start to disagree on a most likely path and its probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backtrack disagreeed with backtrack_log for sequence length  530\n"
     ]
    }
   ],
   "source": [
    "# Your code here ...\n",
    "model = hmm_7_state\n",
    "b3 = True\n",
    "b7 = True\n",
    "for i in range(10, len(x_long), 10):\n",
    "    x = x_long[:i]\n",
    "    z = z_long[:i]\n",
    "\n",
    "    x_trans = translate_observations_to_indices(x)\n",
    "    \n",
    "    # Make your experiment here...\n",
    "    w = compute_w(model, x_trans)\n",
    "    b = backtrack(w, model, x_trans)\n",
    "    \n",
    "    w_log = compute_w_log(model, x_trans)\n",
    "    b_log = backtrack_log(w_log, model, x_trans)\n",
    "    \n",
    "    if (b != b_log).any():\n",
    "        print(\"backtrack disagreeed with backtrack_log for sequence length \", i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Posterior Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have time, try to implement posterior decoding (with scaling, if possible) as explained in the lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 3 3 3 3 3 3 3 3 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2\n",
      " 1 0 2 1 0 2 1 0 2 1 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "def posterior_decoding(model, x):\n",
    "    N, K = len(x), model.init_probs.shape[0]\n",
    "\n",
    "    alpha_hat = np.empty((K, N))\n",
    "    c = np.empty((N,))\n",
    "    beta_hat = np.empty((K, N))\n",
    "    \n",
    "    # do forward pass and calculate c to avoid numerical issues (normalize by c)\n",
    "    \n",
    "    # Basis:\n",
    "    # alpha(z1) = p(z1)p(x1|z1)\n",
    "    alpha_basis = model.init_probs * model.emission_probs[:, x[0]]\n",
    "    # c1 = sum_z1 p(z1)p(x1|z1)\n",
    "    c[0] = (alpha_basis).sum()\n",
    "    alpha_hat[:, 0] = alpha_basis / c[0]\n",
    "    \n",
    "    for n in range(1, N):\n",
    "        # delta(z_n) = p(xn|zn) sum_{zn-1} alpha_hat(z_n-1)p(zn|zn-1)\n",
    "        delta = model.emission_probs[:, x[n]] * (model.trans_probs.T * alpha_hat[:, n-1]).sum(axis=1)\n",
    "        # cn = sum_K delta(z_n)\n",
    "        c[n] = delta.sum()\n",
    "        # alpha_hat(z_n) = delta(z_n)/cn\n",
    "        alpha_hat[:, n] = delta / c[n]\n",
    "        \n",
    "    # do backwards pass\n",
    "    # Basis: beta_hat(zN) = 1\n",
    "    beta_hat[:, -1] = 1 \n",
    "    for n in range(N-2, -1, -1):\n",
    "        # epsilon(zn) = sum_{zn+1} beta_hat(zn+1)p(xn+1|zn+1)p(zn+1|zn)\n",
    "        eps = (beta_hat[:, n+1] * model.emission_probs[:, x[n+1]] * model.trans_probs).sum(axis=1)\n",
    "        beta_hat[:, n] = eps / c[n+1]\n",
    "    \n",
    "    z = (alpha_hat * beta_hat).argmax(axis=0)\n",
    "    \n",
    "    return z\n",
    "\n",
    "forward(hmm_7_state, translate_observations_to_indices(x_short))\n",
    "print(posterior_decoding(hmm_7_state, translate_observations_to_indices(x_short)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the Viterbi and posterior decodings for the `x_short` and `x_long` using the 7-state model (`hmm_7_state`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_short\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2\n",
      " 1 0 2 1 0 2 1 0 2 1 0 2 1]\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2\n",
      " 1 0 2 1 0 2 1 0 2 1 0 2 1]\n",
      "x_long\n",
      "Viterbi and Posterior disagreed at index 5\n",
      "Viterbi and Posterior disagreed at index 6\n",
      "Viterbi and Posterior disagreed at index 7\n",
      "Viterbi and Posterior disagreed at index 8\n",
      "Viterbi and Posterior disagreed at index 9\n",
      "Viterbi and Posterior disagreed at index 10\n",
      "Viterbi and Posterior disagreed at index 11\n",
      "Viterbi and Posterior disagreed at index 12\n",
      "Viterbi and Posterior disagreed at index 13\n",
      "Viterbi and Posterior disagreed at index 14\n",
      "Viterbi and Posterior disagreed at index 15\n",
      "Viterbi and Posterior disagreed at index 16\n",
      "Viterbi and Posterior disagreed at index 17\n",
      "Viterbi and Posterior disagreed at index 18\n",
      "Viterbi and Posterior disagreed at index 19\n",
      "Viterbi and Posterior disagreed at index 20\n",
      "Viterbi and Posterior disagreed at index 21\n",
      "Viterbi and Posterior disagreed at index 22\n",
      "Viterbi and Posterior disagreed at index 23\n",
      "Viterbi and Posterior disagreed at index 24\n",
      "Viterbi and Posterior disagreed at index 25\n",
      "Viterbi and Posterior disagreed at index 38\n",
      "Viterbi and Posterior disagreed at index 40\n",
      "Viterbi and Posterior disagreed at index 41\n",
      "Viterbi and Posterior disagreed at index 42\n",
      "Viterbi and Posterior disagreed at index 43\n",
      "Viterbi and Posterior disagreed at index 44\n",
      "Viterbi and Posterior disagreed at index 45\n",
      "Viterbi and Posterior disagreed at index 46\n",
      "Viterbi and Posterior disagreed at index 47\n",
      "Viterbi and Posterior disagreed at index 48\n",
      "Viterbi and Posterior disagreed at index 49\n",
      "Viterbi and Posterior disagreed at index 50\n",
      "Viterbi and Posterior disagreed at index 51\n",
      "Viterbi and Posterior disagreed at index 52\n",
      "Viterbi and Posterior disagreed at index 53\n",
      "Viterbi and Posterior disagreed at index 54\n",
      "Viterbi and Posterior disagreed at index 55\n",
      "Viterbi and Posterior disagreed at index 56\n",
      "Viterbi and Posterior disagreed at index 57\n",
      "Viterbi and Posterior disagreed at index 58\n",
      "Viterbi and Posterior disagreed at index 59\n",
      "Viterbi and Posterior disagreed at index 60\n",
      "Viterbi and Posterior disagreed at index 61\n",
      "Viterbi and Posterior disagreed at index 62\n",
      "Viterbi and Posterior disagreed at index 63\n",
      "Viterbi and Posterior disagreed at index 64\n",
      "Viterbi and Posterior disagreed at index 65\n",
      "Viterbi and Posterior disagreed at index 66\n",
      "Viterbi and Posterior disagreed at index 67\n",
      "Viterbi and Posterior disagreed at index 68\n",
      "Viterbi and Posterior disagreed at index 69\n",
      "Viterbi and Posterior disagreed at index 70\n",
      "Viterbi and Posterior disagreed at index 81\n",
      "Viterbi and Posterior disagreed at index 82\n",
      "Viterbi and Posterior disagreed at index 83\n",
      "Viterbi and Posterior disagreed at index 86\n",
      "Viterbi and Posterior disagreed at index 192\n",
      "Viterbi and Posterior disagreed at index 193\n",
      "Viterbi and Posterior disagreed at index 194\n",
      "Viterbi and Posterior disagreed at index 195\n",
      "Viterbi and Posterior disagreed at index 196\n",
      "Viterbi and Posterior disagreed at index 197\n",
      "Viterbi and Posterior disagreed at index 198\n",
      "Viterbi and Posterior disagreed at index 199\n",
      "Viterbi and Posterior disagreed at index 200\n",
      "Viterbi and Posterior disagreed at index 201\n",
      "Viterbi and Posterior disagreed at index 202\n",
      "Viterbi and Posterior disagreed at index 203\n",
      "Viterbi and Posterior disagreed at index 204\n",
      "Viterbi and Posterior disagreed at index 205\n",
      "Viterbi and Posterior disagreed at index 206\n",
      "Viterbi and Posterior disagreed at index 207\n",
      "Viterbi and Posterior disagreed at index 208\n",
      "Viterbi and Posterior disagreed at index 209\n",
      "Viterbi and Posterior disagreed at index 210\n",
      "Viterbi and Posterior disagreed at index 310\n",
      "Viterbi and Posterior disagreed at index 311\n",
      "Viterbi and Posterior disagreed at index 313\n",
      "Viterbi and Posterior disagreed at index 314\n",
      "Viterbi and Posterior disagreed at index 332\n",
      "Viterbi and Posterior disagreed at index 333\n",
      "Viterbi and Posterior disagreed at index 334\n",
      "Viterbi and Posterior disagreed at index 335\n",
      "Viterbi and Posterior disagreed at index 336\n",
      "Viterbi and Posterior disagreed at index 337\n",
      "Viterbi and Posterior disagreed at index 338\n",
      "Viterbi and Posterior disagreed at index 339\n",
      "Viterbi and Posterior disagreed at index 340\n",
      "Viterbi and Posterior disagreed at index 369\n",
      "Viterbi and Posterior disagreed at index 370\n",
      "Viterbi and Posterior disagreed at index 371\n",
      "Viterbi and Posterior disagreed at index 372\n",
      "Viterbi and Posterior disagreed at index 373\n",
      "Viterbi and Posterior disagreed at index 374\n",
      "Viterbi and Posterior disagreed at index 375\n",
      "Viterbi and Posterior disagreed at index 376\n",
      "Viterbi and Posterior disagreed at index 377\n",
      "Viterbi and Posterior disagreed at index 378\n",
      "Viterbi and Posterior disagreed at index 379\n",
      "Viterbi and Posterior disagreed at index 380\n",
      "Viterbi and Posterior disagreed at index 381\n",
      "Viterbi and Posterior disagreed at index 382\n",
      "Viterbi and Posterior disagreed at index 383\n",
      "Viterbi and Posterior disagreed at index 384\n",
      "Viterbi and Posterior disagreed at index 385\n",
      "Viterbi and Posterior disagreed at index 386\n",
      "Viterbi and Posterior disagreed at index 387\n",
      "Viterbi and Posterior disagreed at index 388\n",
      "Viterbi and Posterior disagreed at index 389\n",
      "Viterbi and Posterior disagreed at index 390\n",
      "Viterbi and Posterior disagreed at index 391\n",
      "Viterbi and Posterior disagreed at index 392\n",
      "Viterbi and Posterior disagreed at index 395\n",
      "Viterbi and Posterior disagreed at index 477\n",
      "Viterbi and Posterior disagreed at index 478\n",
      "Viterbi and Posterior disagreed at index 479\n",
      "Viterbi and Posterior disagreed at index 480\n",
      "Viterbi and Posterior disagreed at index 481\n",
      "Viterbi and Posterior disagreed at index 482\n",
      "Viterbi and Posterior disagreed at index 483\n",
      "Viterbi and Posterior disagreed at index 484\n",
      "Viterbi and Posterior disagreed at index 485\n",
      "Viterbi and Posterior disagreed at index 486\n",
      "Viterbi and Posterior disagreed at index 487\n",
      "Viterbi and Posterior disagreed at index 488\n",
      "Viterbi and Posterior disagreed at index 489\n",
      "Viterbi and Posterior disagreed at index 490\n",
      "Viterbi and Posterior disagreed at index 491\n",
      "Viterbi and Posterior disagreed at index 492\n",
      "Viterbi and Posterior disagreed at index 493\n",
      "Viterbi and Posterior disagreed at index 494\n",
      "Viterbi and Posterior disagreed at index 495\n",
      "Viterbi and Posterior disagreed at index 496\n",
      "Viterbi and Posterior disagreed at index 497\n",
      "Viterbi and Posterior disagreed at index 498\n",
      "Viterbi and Posterior disagreed at index 499\n",
      "Viterbi and Posterior disagreed at index 500\n",
      "Viterbi and Posterior disagreed at index 501\n",
      "Viterbi and Posterior disagreed at index 502\n",
      "Viterbi and Posterior disagreed at index 503\n",
      "Viterbi and Posterior disagreed at index 504\n",
      "Viterbi and Posterior disagreed at index 505\n",
      "Viterbi and Posterior disagreed at index 506\n",
      "Viterbi and Posterior disagreed at index 507\n",
      "Viterbi and Posterior disagreed at index 508\n",
      "Viterbi and Posterior disagreed at index 509\n",
      "Viterbi and Posterior disagreed at index 510\n",
      "Viterbi and Posterior disagreed at index 511\n",
      "Viterbi and Posterior disagreed at index 512\n",
      "Viterbi and Posterior disagreed at index 513\n",
      "Viterbi and Posterior disagreed at index 514\n",
      "Viterbi and Posterior disagreed at index 515\n",
      "Viterbi and Posterior disagreed at index 516\n",
      "Viterbi and Posterior disagreed at index 517\n",
      "Viterbi and Posterior disagreed at index 518\n",
      "Viterbi and Posterior disagreed at index 519\n",
      "Viterbi and Posterior disagreed at index 520\n",
      "Viterbi and Posterior disagreed at index 521\n",
      "Viterbi and Posterior disagreed at index 522\n",
      "Viterbi and Posterior disagreed at index 523\n",
      "Viterbi and Posterior disagreed at index 524\n",
      "Viterbi and Posterior disagreed at index 525\n",
      "Viterbi and Posterior disagreed at index 526\n",
      "Viterbi and Posterior disagreed at index 527\n",
      "Viterbi and Posterior disagreed at index 528\n",
      "Viterbi and Posterior disagreed at index 529\n",
      "Viterbi and Posterior disagreed at index 530\n",
      "Viterbi and Posterior disagreed at index 531\n",
      "Viterbi and Posterior disagreed at index 532\n",
      "Viterbi and Posterior disagreed at index 533\n",
      "Viterbi and Posterior disagreed at index 534\n",
      "Viterbi and Posterior disagreed at index 535\n",
      "Viterbi and Posterior disagreed at index 536\n",
      "Viterbi and Posterior disagreed at index 537\n",
      "Viterbi and Posterior disagreed at index 538\n",
      "Viterbi and Posterior disagreed at index 539\n",
      "Viterbi and Posterior disagreed at index 540\n",
      "Viterbi and Posterior disagreed at index 541\n",
      "Viterbi and Posterior disagreed at index 542\n",
      "Viterbi and Posterior disagreed at index 543\n",
      "Viterbi and Posterior disagreed at index 544\n",
      "Viterbi and Posterior disagreed at index 545\n",
      "Viterbi and Posterior disagreed at index 546\n",
      "Viterbi and Posterior disagreed at index 547\n",
      "Viterbi and Posterior disagreed at index 548\n",
      "Viterbi and Posterior disagreed at index 549\n",
      "Viterbi and Posterior disagreed at index 550\n",
      "Viterbi and Posterior disagreed at index 551\n",
      "Viterbi and Posterior disagreed at index 552\n",
      "Viterbi and Posterior disagreed at index 553\n",
      "Viterbi and Posterior disagreed at index 554\n",
      "Viterbi and Posterior disagreed at index 555\n",
      "Viterbi and Posterior disagreed at index 556\n",
      "Viterbi and Posterior disagreed at index 557\n",
      "Viterbi and Posterior disagreed at index 558\n",
      "Viterbi and Posterior disagreed at index 559\n",
      "Viterbi and Posterior disagreed at index 560\n",
      "Viterbi and Posterior disagreed at index 561\n",
      "Viterbi and Posterior disagreed at index 562\n",
      "Viterbi and Posterior disagreed at index 563\n",
      "Viterbi and Posterior disagreed at index 564\n",
      "Viterbi and Posterior disagreed at index 565\n",
      "Viterbi and Posterior disagreed at index 566\n",
      "Viterbi and Posterior disagreed at index 621\n",
      "Viterbi and Posterior disagreed at index 624\n",
      "Viterbi and Posterior disagreed at index 625\n",
      "Viterbi and Posterior disagreed at index 627\n",
      "Viterbi and Posterior disagreed at index 628\n",
      "Viterbi and Posterior disagreed at index 629\n",
      "Viterbi and Posterior disagreed at index 630\n",
      "Viterbi and Posterior disagreed at index 631\n",
      "Viterbi and Posterior disagreed at index 632\n",
      "Viterbi and Posterior disagreed at index 633\n",
      "Viterbi and Posterior disagreed at index 634\n",
      "Viterbi and Posterior disagreed at index 635\n",
      "Viterbi and Posterior disagreed at index 636\n",
      "Viterbi and Posterior disagreed at index 637\n",
      "Viterbi and Posterior disagreed at index 638\n",
      "Viterbi and Posterior disagreed at index 639\n",
      "Viterbi and Posterior disagreed at index 640\n",
      "Viterbi and Posterior disagreed at index 641\n",
      "Viterbi and Posterior disagreed at index 642\n",
      "Viterbi and Posterior disagreed at index 643\n",
      "Viterbi and Posterior disagreed at index 644\n",
      "Viterbi and Posterior disagreed at index 645\n",
      "Viterbi and Posterior disagreed at index 646\n",
      "Viterbi and Posterior disagreed at index 647\n",
      "Viterbi and Posterior disagreed at index 648\n",
      "Viterbi and Posterior disagreed at index 649\n",
      "Viterbi and Posterior disagreed at index 650\n",
      "Viterbi and Posterior disagreed at index 651\n",
      "Viterbi and Posterior disagreed at index 652\n",
      "Viterbi and Posterior disagreed at index 653\n",
      "Viterbi and Posterior disagreed at index 654\n",
      "Viterbi and Posterior disagreed at index 655\n",
      "Viterbi and Posterior disagreed at index 656\n",
      "Viterbi and Posterior disagreed at index 657\n",
      "Viterbi and Posterior disagreed at index 658\n",
      "Viterbi and Posterior disagreed at index 659\n",
      "Viterbi and Posterior disagreed at index 660\n",
      "Viterbi and Posterior disagreed at index 661\n",
      "Viterbi and Posterior disagreed at index 662\n",
      "Viterbi and Posterior disagreed at index 663\n",
      "Viterbi and Posterior disagreed at index 664\n",
      "Viterbi and Posterior disagreed at index 665\n",
      "Viterbi and Posterior disagreed at index 667\n",
      "Viterbi and Posterior disagreed at index 668\n",
      "Viterbi and Posterior disagreed at index 711\n",
      "Viterbi and Posterior disagreed at index 714\n",
      "Viterbi and Posterior disagreed at index 715\n",
      "Viterbi and Posterior disagreed at index 716\n",
      "Viterbi and Posterior disagreed at index 840\n",
      "Viterbi and Posterior disagreed at index 841\n",
      "Viterbi and Posterior disagreed at index 842\n",
      "Viterbi and Posterior disagreed at index 843\n",
      "Viterbi and Posterior disagreed at index 844\n",
      "Viterbi and Posterior disagreed at index 845\n",
      "Viterbi and Posterior disagreed at index 846\n",
      "Viterbi and Posterior disagreed at index 847\n",
      "Viterbi and Posterior disagreed at index 848\n",
      "Viterbi and Posterior disagreed at index 849\n",
      "Viterbi and Posterior disagreed at index 850\n",
      "Viterbi and Posterior disagreed at index 851\n",
      "Viterbi and Posterior disagreed at index 852\n",
      "Viterbi and Posterior disagreed at index 853\n",
      "Viterbi and Posterior disagreed at index 854\n",
      "Viterbi and Posterior disagreed at index 855\n",
      "Viterbi and Posterior disagreed at index 856\n",
      "Viterbi and Posterior disagreed at index 857\n",
      "Viterbi and Posterior disagreed at index 858\n",
      "Viterbi and Posterior disagreed at index 859\n",
      "Viterbi and Posterior disagreed at index 860\n",
      "Viterbi and Posterior disagreed at index 861\n",
      "Viterbi and Posterior disagreed at index 862\n",
      "Viterbi and Posterior disagreed at index 863\n",
      "Viterbi and Posterior disagreed at index 864\n",
      "Viterbi and Posterior disagreed at index 865\n",
      "Viterbi and Posterior disagreed at index 866\n",
      "Viterbi and Posterior disagreed at index 867\n",
      "Viterbi and Posterior disagreed at index 868\n",
      "Viterbi and Posterior disagreed at index 933\n",
      "Viterbi and Posterior disagreed at index 934\n",
      "Viterbi and Posterior disagreed at index 935\n",
      "Viterbi and Posterior disagreed at index 937\n",
      "Viterbi and Posterior disagreed at index 938\n",
      "Viterbi and Posterior disagreed at index 939\n",
      "Viterbi and Posterior disagreed at index 940\n",
      "Viterbi and Posterior disagreed at index 941\n",
      "Viterbi and Posterior disagreed at index 942\n",
      "Viterbi and Posterior disagreed at index 943\n",
      "Viterbi and Posterior disagreed at index 944\n",
      "Viterbi and Posterior disagreed at index 945\n",
      "Viterbi and Posterior disagreed at index 946\n",
      "Viterbi and Posterior disagreed at index 947\n",
      "Viterbi and Posterior disagreed at index 948\n",
      "Viterbi and Posterior disagreed at index 949\n",
      "Viterbi and Posterior disagreed at index 950\n",
      "Viterbi and Posterior disagreed at index 951\n",
      "Viterbi and Posterior disagreed at index 952\n",
      "Viterbi and Posterior disagreed at index 953\n",
      "Viterbi and Posterior disagreed at index 954\n",
      "Viterbi and Posterior disagreed at index 955\n",
      "Viterbi and Posterior disagreed at index 956\n",
      "Viterbi and Posterior disagreed at index 957\n",
      "Viterbi and Posterior disagreed at index 959\n",
      "Viterbi and Posterior disagreed at index 960\n",
      "Viterbi and Posterior disagreed at index 963\n"
     ]
    }
   ],
   "source": [
    "# Your code here ...\n",
    "model = hmm_7_state\n",
    "\n",
    "print(\"x_short\")\n",
    "x_trans = translate_observations_to_indices(x_short)\n",
    "z_trans = translate_path_to_indices(z_short)\n",
    "\n",
    "posterior_path = posterior_decoding(model, x_trans)\n",
    "w = compute_w_log(model, x_trans)\n",
    "viterbi_path = backtrack_log(w, model, x_trans)\n",
    "print(posterior_path)\n",
    "print(viterbi_path)\n",
    "\n",
    "for idx, (i, j) in enumerate(zip(posterior_path, viterbi_path)):\n",
    "    if i != j:\n",
    "        print(\"Viterbi and Posterior disagreed at index\", idx)\n",
    "\n",
    "\n",
    "print(\"x_long\")\n",
    "x_trans = translate_observations_to_indices(x_long)\n",
    "z_trans = translate_path_to_indices(z_long)\n",
    "\n",
    "posterior_path = posterior_decoding(model, x_trans)\n",
    "w = compute_w_log(model, x_trans)\n",
    "viterbi_path = backtrack_log(w, model, x_trans)\n",
    "\n",
    "for idx, (i, j) in enumerate(zip(posterior_path, viterbi_path)):\n",
    "    if i != j:\n",
    "        print(\"Viterbi and Posterior disagreed at index\", idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
